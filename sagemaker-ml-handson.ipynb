{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このハンズオンでやること\n",
    "- S3からRedshiftにロードされたSalesデータをSageMakerに取得する\n",
    "- SageMaker上でデータの可視化やデータ加工を行う\n",
    "- 広く利用されている機械学習ライブラリーである、Scikit-Learnを使ったモデル構築を試してみる\n",
    "- 構築したモデルをSageMakerの推論Endpointとしてデプロイし、推論APIを構築する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS上でデータ操作を行うために便利なライブラリーを追加インストールする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"MediumSlateBlue\">1. データを理解する</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接続先のデータベース情報をセットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = 'xxxx'\n",
    "db_name = 'xxxx'\n",
    "cluster_name = 'redshift-redshiftcluster-xxxxxxxx'\n",
    "cluster_endpoint = 'redshift-redshiftcluster-xxxxxxxxxxxxxxxxx.xxxxxxxxxx.redshift.amazonaws.com'\n",
    "db_port = 5439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユーザーIDとパスワードは一時クレデンシャルを取得する\n",
    "\n",
    "参考：\n",
    "https://aws.amazon.com/jp/blogs/news/build-fast-flexible-secure-machine-learning-platform-using-amazon-sagemaker-and-amazon-redshift/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = boto3.client('redshift')\n",
    "credentials = redshift.get_cluster_credentials(\n",
    "    DbUser=db_user, \n",
    "    DbName=db_name, \n",
    "    ClusterIdentifier=cluster_name, \n",
    "    DurationSeconds=3600,\n",
    "    AutoCreate=False\n",
    ")\n",
    "\n",
    "tmp_db_user = credentials['DbUser']\n",
    "tmp_db_password = credentials['DbPassword']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接続先の情報と一時クレデンシャルを利用してDB接続を確立する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=cluster_endpoint, \n",
    "    port=db_port, \n",
    "    dbname=db_name, \n",
    "    user=tmp_db_user, \n",
    "    password=tmp_db_password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RedShiftに格納されたjson_salesの件数を確認する\n",
    "# この関数はPandas DataFrameを戻すが、表示させるだけの場合は変数に格納する必要はない\n",
    "pd.read_sql(\n",
    "    sql=\"select count(*) as sales_count from sh10.sales\",\n",
    "    con=conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 少量のデータを取得してJupyter上で参照する\n",
    "pd.read_sql(\n",
    "    sql=\"select * from sh10.sales where prod_id is not null limit 5\",\n",
    "    con=conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 後続処理で利用するデータは変数に格納する\n",
    "# ここでは全期間のamaount_soldを日ごとに合計する処理をRedshiftで行い、サマリーした結果をJupyter上で保持する\n",
    "df_sales_daily = pd.read_sql(\n",
    "    sql=\"select time_id, sum(amount_sold) as daily_sum from sh10.sales \\\n",
    "         where prod_id is not null \\\n",
    "         group by time_id order by time_id\",\n",
    "    con=conn\n",
    ")\n",
    "print('取得したデータの件数（日数）: {}'.format(df_sales_daily.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_daily.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 月単位の売り上げを集計してグラフ化する\n",
    "df_sales_daily['time_id'] = pd.to_datetime(df_sales_daily.time_id)\n",
    "df_sales_daily.set_index('time_id', inplace=True)\n",
    "df_sales_monthly = df_sales_daily.resample('M').sum()\n",
    "\n",
    "df_sales_monthly.rename(columns={'daily_sum':'monthly_sum'}, inplace=True)\n",
    "df_sales_monthly.plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"MediumSlateBlue\">2. データを加工する</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 過去の実績値の推移を入力データにするため、1ヶ月前、2ヶ月前、3ヶ月前、12ヶ月前の実績値をレコード内に横持ちで保持する\n",
    "df_data = df_sales_monthly['2007-01-01':].copy()\n",
    "df_data['monthly_sum'] = df_data.monthly_sum / 1000000\n",
    "df_data['1month_ago'] = df_data.monthly_sum.shift(1)\n",
    "df_data['2month_ago'] = df_data.monthly_sum.shift(2)\n",
    "df_data['3month_ago'] = df_data.monthly_sum.shift(3)\n",
    "df_data['12month_ago'] = df_data.monthly_sum.shift(12)\n",
    "\n",
    "# 過去のデータをシフトしているため、期間の開始から12レコード分は欠損値が発生する\n",
    "df_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値が発生した部分のデータは削除する\n",
    "df_data = df_data['2008-01-01':].copy()\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"MediumSlateBlue\">3. モデルを構築する</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# モデルのトレーニングを行う鑵子を定義する\n",
    "def train_lr_model(feature_cols, target_col, train_test_split):\n",
    "    # 学習データとテストデータを分離\n",
    "    train_x = df_data[:train_test_split][feature_cols].values\n",
    "    train_y = df_data[:train_test_split][[target_col]].values\n",
    "    train_index = df_data[:train_test_split].index\n",
    "    test_x = df_data[train_test_split:][feature_cols].values\n",
    "    test_y = df_data[train_test_split:][[target_col]].values\n",
    "    test_index = df_data[train_test_split:].index\n",
    "\n",
    "    # モデルのトレーニングを実行\n",
    "    lr_model = LinearRegression(normalize=True)\n",
    "    lr_model.fit(train_x, train_y)\n",
    "\n",
    "    # テストデータに対して予測を実行\n",
    "    test_pred = lr_model.predict(test_x)\n",
    "\n",
    "    # 実績データと予測結果を結合して返却\n",
    "    df_test = pd.DataFrame({'label': test_y[:,0], \n",
    "                            'pred': test_pred[:,0]}, index=test_index)\n",
    "    df_train = pd.DataFrame({'label': train_y[:,0], \n",
    "                           }, index=train_index)\n",
    "    df_result = pd.concat([df_train, df_test], sort=False).sort_index()\n",
    "\n",
    "    return lr_model, df_test, df_result\n",
    "\n",
    "# 1回目のモデル作成試行\n",
    "feature_cols1 = ['1month_ago', '2month_ago', '3month_ago', '12month_ago']\n",
    "target_col = 'monthly_sum'\n",
    "train_test_split = '2011-12-31'\n",
    "\n",
    "model1, df_test1, df_result1 = train_lr_model(feature_cols1, target_col, train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('r2', r2_score(df_test1.label, df_test1.pred))\n",
    "df_result1.plot(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル1の予測傾向\n",
    "- r2乗値は約0.76となった\n",
    "- 2012年の予測はある程度実績に追随している\n",
    "- 2013年は、2012年までの増加傾向を反映して上振れした予測値となっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"MediumSlateBlue\">3-2. モデルの改善を試みる</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 年々増えていたり、月ごとに周期的な動きをしている傾向を取り込みたい\n",
    "# そのために特徴量を追加する\n",
    "\n",
    "df_data.reset_index(inplace=True)\n",
    "\n",
    "df_data['month'] = df_data.time_id.dt.month\n",
    "starting_year = df_data.time_id.dt.year.min()\n",
    "df_data['year_delta'] = df_data.time_id.dt.year - starting_year\n",
    "df_data.set_index('time_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もう一度モデルの学習を実行\n",
    "feature_cols2 = ['1month_ago', '2month_ago', '3month_ago', '12month_ago', 'month', 'year_delta']\n",
    "model2, df_test2, df_result2 = train_lr_model(feature_cols2, target_col, train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('r2', r2_score(df_test2.label, df_test2.pred))\n",
    "df_result2.plot(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル2の予測傾向\n",
    "- r2乗値は約0.84に増加して、全体としての予実差は改善された\n",
    "- 2013年の上振れ傾向は是正されているが、2012年がやや下振れした予測となった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルはどんなパラメーターが算出されたのか\n",
    "def WriteCoef(model, feature_cols):\n",
    "    [print('coefficient[', v, ']=', model.coef_[0][i]) for i, v in enumerate(feature_cols)]\n",
    "    print('intercept = ', model.intercept_)\n",
    "    \n",
    "print('model1:')\n",
    "WriteCoef(model1, feature_cols1)\n",
    "print()\n",
    "print('model2:')\n",
    "WriteCoef(model2, feature_cols2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"MediumSlateBlue\">4. モデルを推論用に展開する</font>\n",
    "推論APIをデプロイするために、SageMakerの機能を利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Sagemaker session object\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Sagemakerの実行ロールを取得\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3上のデータ出力先を定義\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = 'sagemaker-handson'\n",
    "s3_path = 's3://{}/{}/monthly_sum'.format(default_bucket, s3_prefix)\n",
    "\n",
    "out_cols = ['monthly_sum', '1month_ago', '2month_ago', '3month_ago', '12month_ago', 'month', 'year_delta']\n",
    "df_train_estimator = df_data[:train_test_split][out_cols]\n",
    "df_test_estimator = df_data[train_test_split:][out_cols]\n",
    "\n",
    "# 加工したデータをSageMakerの保持するストレージ（EBS）に保存する\n",
    "df_train_estimator.to_csv('training_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存したファイルをCLIコマンドでS3にコピーする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp 'training_data.csv' $s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'sklearn_monthly_sum.py'\n",
    "\n",
    "# scikit-learnを利用したモデル学習のパラメータ指定\n",
    "# ここでは時間を短縮するために、Notebookを稼働しているインスタンス内（local）で学習する設定となっている\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"local\",\n",
    "    role=role,\n",
    "    hyperparameters={'normalize': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【参考】大量のデータを使用する重い学習に、学習用の別インスタンスを利用する場合は以下のように記述する\n",
    "```python\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'sklearn_monthly_sum.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",      # 学習に利用するインスタンスタイプを指定\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,     # SageMakerの機能を利用するためのSessionオブジェクトを指定\n",
    "    hyperparameters={'normalize': True})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# S3に出力したデータを指定してモデルを学習させる\n",
    "sklearn.fit({'train': s3_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論Endpointをdeployし、APIとして利用可能にする。ここでもNotebookインスタンス内（local）に構築する\n",
    "# Deployメソッドの戻り値は、predictorとして利用できる\n",
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【参考】実運用に利用するEndpointをdeployする際はインスタンスタイプの記述を変更する\n",
    "```python\n",
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=\"MediumSlateBlue\">5. Deployした推論Endpointを使用してpredictionを行う</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_estimator.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimatorに合わせたテスト用の推論データを作成する\n",
    "test_x = df_test_estimator.values[:,1:]\n",
    "test_y = df_test_estimator.values[:,0]\n",
    "\n",
    "# テスト用の推論データ（説明変数）をPredictorに引き渡し、予測結果を得る\n",
    "pred = predictor.predict(test_x)\n",
    "\n",
    "# 正解（label）と予測結果（pred）を併せて、精度評価用のDataFrameを作成する\n",
    "df_test_result = pd.DataFrame({'label':test_y, 'pred':pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrameのplot機能を利用すると、予実が簡単に比較できる\n",
    "df_test_result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint が起動されていると料金が発生するので、最後に削除する\n",
    "sklearn.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
